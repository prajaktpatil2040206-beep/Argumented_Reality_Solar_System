<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <title>AR Cube â€“ Sensor Driven</title>
    <style>
        body {
            margin: 0;
            overflow: hidden;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            touch-action: none;
            background: black;
        }
        #video-bg {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            object-fit: cover;
            z-index: 0;
            pointer-events: none;
        }
        #canvas-container {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            z-index: 1;
            pointer-events: none; /* allow touches to pass to any UI */
        }
        #sensor-status {
            position: absolute;
            bottom: 30px;
            left: 20px;
            right: 20px;
            text-align: center;
            color: white;
            background: rgba(0,0,0,0.5);
            backdrop-filter: blur(5px);
            padding: 10px 18px;
            border-radius: 40px;
            width: fit-content;
            margin: 0 auto;
            z-index: 2;
            font-size: 15px;
            border: 1px solid rgba(255,255,255,0.2);
            pointer-events: none;
        }
        #permission-btn {
            position: absolute;
            top: 20px;
            right: 20px;
            z-index: 3;
            background: #1e2a3a;
            color: white;
            border: 2px solid #4aa3ff;
            border-radius: 40px;
            padding: 12px 24px;
            font-size: 16px;
            font-weight: bold;
            box-shadow: 0 4px 15px rgba(0,0,0,0.5);
            display: none;
            cursor: pointer;
            pointer-events: auto;
        }
    </style>
</head>
<body>
    <video id="video-bg" autoplay playsinline></video>
    <div id="canvas-container"></div>
    <button id="permission-btn">ðŸ”˜ Enable Motion Sensors</button>
    <div id="sensor-status">ðŸŒ€ Initializing sensors...</div>

    <script type="importmap">
        {
            "imports": {
                "three": "https://unpkg.com/three@0.128.0/build/three.module.js"
            }
        }
    </script>

    <script type="module">
        import * as THREE from 'three';

        // --- 1. Camera feed ---
        const video = document.getElementById('video-bg');
        async function startCamera() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    video: { facingMode: 'environment' }, // rear camera
                    audio: false 
                });
                video.srcObject = stream;
                await video.play();
            } catch (err) {
                document.getElementById('sensor-status').innerText = 'âŒ Camera access denied';
            }
        }
        startCamera();

        // --- 2. Three.js setup (transparent) ---
        const container = document.getElementById('canvas-container');
        const scene = new THREE.Scene();
        scene.background = null; // transparent

        const camera = new THREE.PerspectiveCamera(65, window.innerWidth / window.innerHeight, 0.1, 1000);
        camera.position.set(0, 0, 0); // camera at origin

        const renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
        renderer.setSize(window.innerWidth, window.innerHeight);
        renderer.setPixelRatio(Math.min(window.devicePixelRatio, 2));
        renderer.setClearColor(0x000000, 0); // fully transparent
        container.appendChild(renderer.domElement);

        // --- 3. Lighting ---
        const ambientLight = new THREE.AmbientLight(0xffffff, 0.7);
        scene.add(ambientLight);

        const dirLight = new THREE.DirectionalLight(0xffffff, 1.2);
        dirLight.position.set(1, 2, 3);
        scene.add(dirLight);

        const backLight = new THREE.PointLight(0x4466aa, 0.5);
        backLight.position.set(-2, 1, -3);
        scene.add(backLight);

        // --- 4. Create a group to hold our 3D object (so we can rotate it as a whole) ---
        const arGroup = new THREE.Group();
        scene.add(arGroup);

        // Place the group at a fixed distance in front of the camera (2 meters away)
        arGroup.position.set(0, 0, -2);

        // --- 5. Create a 3D cube with different colors per face (so orientation is obvious) ---
        const cubeSize = 0.8;
        // Use an array of materials for each face
        const colors = [
            0xff3333, // right - red
            0x33ff33, // left - green
            0x3333ff, // top - blue
            0xffff33, // bottom - yellow
            0xff33ff, // front - magenta
            0x33ffff  // back - cyan
        ];
        const materials = colors.map(c => new THREE.MeshStandardMaterial({ color: c, roughness: 0.2, metalness: 0.1 }));
        const geometry = new THREE.BoxGeometry(cubeSize, cubeSize, cubeSize);
        const cube = new THREE.Mesh(geometry, materials);
        arGroup.add(cube);

        // Add a small sphere inside or something? Not needed.

        // --- 6. Device orientation handling ---
        let orientationAvailable = false;
        const statusEl = document.getElementById('sensor-status');
        const permissionBtn = document.getElementById('permission-btn');

        // Target quaternion for the group (inverse of device orientation)
        let targetQuat = new THREE.QUaternion();

        function handleOrientation(event) {
            if (event.alpha === null || event.beta === null || event.gamma === null) return;

            const degToRad = Math.PI / 180;
            const alpha = event.alpha * degToRad; // rotation around Z (compass)
            const beta = event.beta * degToRad;   // front/back tilt
            const gamma = event.gamma * degToRad;  // left/right tilt

            // Build quaternion from device orientation.
            // We want to rotate the object opposite to the device so it appears fixed.
            // Common mapping: yaw (alpha) around Y, pitch (beta) around X, roll (gamma) around Z.
            // But careful with axes: For a phone in default portrait? We'll use standard.
            // We'll create quaternions for each axis and combine.
            const qYaw = new THREE.Quaternion().setFromAxisAngle(new THREE.Vector3(0, 1, 0), -alpha);
            const qPitch = new THREE.Quaternion().setFromAxisAngle(new THREE.Vector3(1, 0, 0), -beta);
            const qRoll = new THREE.Quaternion().setFromAxisAngle(new THREE.Vector3(0, 0, 1), gamma);
            
            // Compose: yaw * pitch * roll (order matters)
            const rawQuat = qYaw.clone().multiply(qPitch).multiply(qRoll);

            // Smoothing with slerp
            if (!orientationAvailable) {
                targetQuat.copy(rawQuat);
                orientationAvailable = true;
                statusEl.innerText = 'ðŸŸ¢ Sensors active â€“ move phone to see cube rotate';
                permissionBtn.style.display = 'none';
            } else {
                targetQuat.slerp(rawQuat, 0.15); // smooth factor
            }

            // Apply inverse to the group so cube seems fixed in world
            arGroup.quaternion.copy(targetQuat).invert();
        }

        // iOS 13+ permission
        if (typeof DeviceOrientationEvent !== 'undefined' && typeof DeviceOrientationEvent.requestPermission === 'function') {
            permissionBtn.style.display = 'block';
            permissionBtn.addEventListener('click', () => {
                DeviceOrientationEvent.requestPermission()
                    .then(response => {
                        if (response === 'granted') {
                            window.addEventListener('deviceorientation', handleOrientation);
                            statusEl.innerText = 'ðŸŸ¢ Sensors active';
                        } else {
                            statusEl.innerText = 'âŒ Sensor permission denied';
                        }
                    })
                    .catch(console.error);
            });
        } else {
            window.addEventListener('deviceorientation', handleOrientation);
            permissionBtn.style.display = 'none';
        }

        // Fallback message if no data after 4 seconds
        setTimeout(() => {
            if (!orientationAvailable) {
                statusEl.innerText = 'âš ï¸ No orientation data (sensors missing?)';
            }
        }, 4000);

        // --- 7. Animation loop ---
        function animate() {
            requestAnimationFrame(animate);

            // Optional: slight rotation of cube itself for extra effect? Not needed, but could.
            // cube.rotation.y += 0.01; // if we want self-spin, but then orientation gets messy.
            // We'll keep cube static relative to group; group rotation handles AR.

            renderer.render(scene, camera);
        }
        animate();

        // --- 8. Window resize ---
        window.addEventListener('resize', () => {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
        });
    </script>
</body>
</html>